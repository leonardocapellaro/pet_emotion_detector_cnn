{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import dlib\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recortar rosto do animal e salvar a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_path, input_dir, output_dir):\n",
    "    try:\n",
    "        detector = dlib.cnn_face_detection_model_v1('dlib_models/dogHeadDetector.dat')\n",
    "        filename, ext = os.path.splitext(os.path.basename(img_path))\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        dets = detector(img, upsample_num_times=1)\n",
    "        \n",
    "        for i, d in enumerate(dets):\n",
    "\n",
    "            x1, y1 = d.rect.left(), d.rect.top()\n",
    "            x2, y2 = d.rect.right(), d.rect.bottom()\n",
    "            \n",
    "            roi = img[y1:y2, x1:x2]\n",
    "            \n",
    "            output_subdir = os.path.join(output_dir, os.path.relpath(os.path.dirname(img_path), input_dir))\n",
    "            os.makedirs(output_subdir, exist_ok=True)\n",
    "            output_filename = f\"{filename}_face{i+1}.jpg\"\n",
    "            output_path = os.path.join(output_subdir, output_filename)\n",
    "            cv2.imwrite(output_path, cv2.cvtColor(roi, cv2.COLOR_RGB2BGR))\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na imagem {img_path}: {str(e)}\")\n",
    "\n",
    "def process_images_in_directory(input_dir, output_dir):\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        image_paths = []\n",
    "        for root, dirs, files in os.walk(input_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    image_paths.append(img_path)\n",
    "\n",
    "        pool.starmap(process_image, [(img_path, input_dir, output_dir) for img_path in image_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso:\n",
    "input_directory = \"images\"\n",
    "output_directory = \"images_processed\"\n",
    "process_images_in_directory(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 21:56:41.839460: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-25 21:56:41.841182: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-25 21:56:41.883345: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-25 21:56:41.883860: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 21:56:42.567318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/leonardocapellaro/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'images_processed'\n",
    "train_dir = 'images_processed/train'\n",
    "test_dir = 'images_processed/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_old_test_train(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)  # Use rmtree para remover um diretório e seu conteúdo\n",
    "        print(f\"Diretório '{path}' removido com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Diretório '{path}' não existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório 'images_processed/train' removido com sucesso.\n",
      "Diretório 'images_processed/test' removido com sucesso.\n"
     ]
    }
   ],
   "source": [
    "clean_old_test_train(train_dir)\n",
    "clean_old_test_train(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(file):\n",
    "    src_file = os.path.join(src_label_dir, file)\n",
    "    dst_file = os.path.join(train_label_dir, file)\n",
    "    \n",
    "    if not os.path.isfile(src_file):\n",
    "        return\n",
    "    \n",
    "    img = load_img(src_file)  # this is a PIL image\n",
    "    img = img.resize((250, 250))  # Resize the image\n",
    "    img.save(dst_file)  # Save the resized image\n",
    "    \n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (1, 250, 250)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 1, 250, 250)\n",
    "\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                              save_to_dir=train_label_dir, save_prefix='aug', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(src_dir)  #Obteras labels a partir dos subdiretórios\n",
    "\n",
    "for label in labels:\n",
    "    src_label_dir = os.path.join(src_dir, label)\n",
    "    train_label_dir = os.path.join(train_dir, label)\n",
    "    test_label_dir = os.path.join(test_dir, label)\n",
    "    \n",
    "    os.makedirs(train_label_dir, exist_ok=True)\n",
    "    os.makedirs(test_label_dir, exist_ok=True)\n",
    "    \n",
    "    files = os.listdir(src_label_dir)\n",
    "    train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)\n",
    "    \n",
    "    with multiprocessing.Pool() as p:\n",
    "        p.map(generate_and_save_images, train_files)\n",
    "    \n",
    "    for file in test_files:\n",
    "        src_file = os.path.join(src_label_dir, file)\n",
    "        dst_file = os.path.join(test_label_dir, file)\n",
    "        copyfile(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10923 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(250, 250),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1215 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(250, 250),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet - 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model_densenet_121(train_generator, test_generator, num_epochs=30, initial_learning_rate=0.001, final_learning_rate=1e-5):\n",
    "    \n",
    "    #Callback EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                                   patience=15,\n",
    "                                   verbose=1,\n",
    "                                   restore_best_weights=True)\n",
    "    \n",
    "    densenet_base = tf.keras.applications.DenseNet121(weights='imagenet',\n",
    "                                                      include_top=False,\n",
    "                                                      input_shape=(250, 250, 3))\n",
    "    \n",
    "    #Congelar as camadas do DenseNet121\n",
    "    densenet_base.trainable = False\n",
    "    \n",
    "    #Geração do valor de steps\n",
    "    total_training_examples = int(train_generator.samples)\n",
    "    batch_size = train_generator.batch_size\n",
    "    steps_per_epoch = math.ceil(total_training_examples / batch_size)\n",
    "    validation_steps = test_generator.samples // test_generator.batch_size\n",
    "    \n",
    "\n",
    "    model_densenet = tf.keras.models.Sequential([\n",
    "        densenet_base,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    #Taxa de decaimento\n",
    "    decay_rate = (final_learning_rate / initial_learning_rate) ** (1 / num_epochs)\n",
    "    \n",
    "    #Função de agendamento de taxa de aprendizado\n",
    "    def lr_schedule(epoch):\n",
    "        current_learning_rate = initial_learning_rate * (decay_rate ** epoch)\n",
    "        return current_learning_rate\n",
    "    \n",
    "    model_densenet.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    #Função lr_schedule para agendar a taxa de aprendizado\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    history_densenet = model_densenet.fit(train_generator,\n",
    "                                          steps_per_epoch=steps_per_epoch,\n",
    "                                          epochs=num_epochs,\n",
    "                                          validation_data=test_generator,\n",
    "                                          validation_steps=validation_steps,\n",
    "                                          callbacks=[early_stopping, lr_callback])\n",
    "    \n",
    "    return model_densenet, history_densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 22:00:05.558085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-25 22:00:05.558752: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "342/342 [==============================] - 471s 1s/step - loss: 3.2547 - accuracy: 0.5500 - val_loss: 0.8572 - val_accuracy: 0.6410 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 464s 1s/step - loss: 0.8831 - accuracy: 0.6041 - val_loss: 0.8817 - val_accuracy: 0.6529 - lr: 9.5499e-04\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 471s 1s/step - loss: 0.7952 - accuracy: 0.6375 - val_loss: 0.8430 - val_accuracy: 0.6436 - lr: 9.1201e-04\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 460s 1s/step - loss: 0.7309 - accuracy: 0.6683 - val_loss: 0.8424 - val_accuracy: 0.6529 - lr: 8.7096e-04\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 460s 1s/step - loss: 0.6803 - accuracy: 0.6896 - val_loss: 0.8440 - val_accuracy: 0.6427 - lr: 8.3176e-04\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 521s 2s/step - loss: 0.6472 - accuracy: 0.6961 - val_loss: 0.8837 - val_accuracy: 0.6613 - lr: 7.9433e-04\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 498s 1s/step - loss: 0.6423 - accuracy: 0.6972 - val_loss: 0.9190 - val_accuracy: 0.6512 - lr: 7.5858e-04\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 587s 2s/step - loss: 0.5826 - accuracy: 0.7255 - val_loss: 0.9316 - val_accuracy: 0.6199 - lr: 7.2444e-04\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 595s 2s/step - loss: 0.5724 - accuracy: 0.7274 - val_loss: 0.9234 - val_accuracy: 0.6512 - lr: 6.9183e-04\n",
      "Epoch 10/100\n",
      "268/342 [======================>.......] - ETA: 1:52 - loss: 0.5393 - accuracy: 0.7488"
     ]
    }
   ],
   "source": [
    "model_densenet_121, history_densenet_121 = create_and_train_model_densenet_121(train_generator, test_generator, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_densenet_121, test_acc_densenet_121 = model_densenet_121.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc_densenet_121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet 201 - Com decaimento de LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model_densenet_201(train_generator, test_generator, num_epochs=30, initial_learning_rate=0.001, final_learning_rate=1e-5):\n",
    "    \n",
    "    #Callback EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                                  patience=15,\n",
    "                                  verbose=1,\n",
    "                                  restore_best_weights=True)\n",
    "\n",
    "    \n",
    "    densenet_base = tf.keras.applications.DenseNet201(weights='imagenet',\n",
    "                                                      include_top=False,\n",
    "                                                      input_shape=(250, 250, 3))\n",
    "    \n",
    "    #Congelar as camadas do DenseNet201\n",
    "    densenet_base.trainable = False\n",
    "\n",
    "    #Geração do valor de steps\n",
    "    total_training_examples = train_generator.samples\n",
    "    batch_size = train_generator.batch_size\n",
    "    steps_per_epoch = total_training_examples / batch_size\n",
    "    validation_steps = test_generator.samples // test_generator.batch_size\n",
    "\n",
    "    model_densenet = tf.keras.models.Sequential([\n",
    "        densenet_base,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    #Taxa de decaimento da LR\n",
    "    decay_rate = (final_learning_rate / initial_learning_rate) ** (1 / num_epochs)\n",
    "    \n",
    "    #Função de agendamento de taxa de aprendizado\n",
    "    def lr_schedule(epoch):\n",
    "        current_learning_rate = initial_learning_rate * (decay_rate ** epoch)\n",
    "        return current_learning_rate\n",
    "\n",
    "    model_densenet.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),  # Use learning_rate\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    #Função lr_schedule para agendar a taxa de aprendizado\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    history_densenet = model_densenet.fit(train_generator,\n",
    "                                          steps_per_epoch=steps_per_epoch,\n",
    "                                          epochs=num_epochs,\n",
    "                                          validation_data=test_generator,\n",
    "                                          validation_steps=validation_steps,\n",
    "                                          callbacks=[early_stopping, lr_callback])\n",
    "    \n",
    "    return model_densenet, history_densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_densenet_201, history_densenet_201 = create_and_train_model_densenet_201(train_generator, test_generator, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_densenet_201, test_acc_densenet_201 = model_densenet_201.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc_densenet_201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    model.save('cnn_models/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_densenet_121, 'model_densenet_121.h5')\n",
    "save_model(model_densenet_201, 'model_densenet_201.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predizer imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_predict(img_path, target_size=(250, 250)):\n",
    "    try:\n",
    "        detector = dlib.cnn_face_detection_model_v1('dlib_models/dogHeadDetector.dat')\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        dets = detector(img, upsample_num_times=1)\n",
    "\n",
    "        # Se nenhuma detecção de face for encontrada, retorne uma imagem em branco\n",
    "        if len(dets) == 0:\n",
    "            print(\"Não foram encontrados rostos na imagem\")\n",
    "            return np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "        # Desenhe retângulos nas detecções\n",
    "        for i, d in enumerate(dets):\n",
    "            x1, y1 = d.rect.left(), d.rect.top()\n",
    "            x2, y2 = d.rect.right(), d.rect.bottom()\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Converta a imagem resultante de volta para BGR para salvar ou exibir\n",
    "        img_result = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Redimensione a imagem resultante para o tamanho desejado\n",
    "        img_result = cv2.resize(img_result, target_size)\n",
    "\n",
    "        return img_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na imagem {img_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def image_class_predict(model, image_path):\n",
    "    classes = [\"angry\", \"happy\", \"sad\"]\n",
    "    # Carregue e pré-processe a imagem de entrada\n",
    "    img = process_image_predict(image_path)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Normalização (se necessário)\n",
    "\n",
    "    # Faça a previsão\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    # Obtenha a classe prevista\n",
    "    class_index = np.argmax(predictions)\n",
    "\n",
    "    return class_index, classes[class_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado Densenet 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = 'example.jpeg'\n",
    "classe_prevista_index, classe_prevista = image_class_predict(model_densenet_121, imagem)\n",
    "\n",
    "print(f'A imagem é da classe: {classe_prevista}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado Densenet 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = 'example.jpeg'\n",
    "classe_prevista_index, classe_prevista = image_class_predict(model_densenet_201, imagem)\n",
    "\n",
    "print(f'A imagem é da classe: {classe_prevista}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
